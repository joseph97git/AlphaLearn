---
title: "LSTM Analysis"
author: "Joseph Kim"
date: "5/27/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load libraries
library(keras)
library(tensorflow)
library(quantmod)
library(plyr)
library(xts)
```

```{r}
# get data
getSymbols("AAPL", src = "yahoo", from = as.Date('2018-01-01'), to = as.Date('2018-05-20'))
```

```{r}
# visualize data
chartSeries(x = AAPL, subset = '2018-01-01::2018-05-20', type = "candlesticks", theme = chartTheme("white"), up.col = "green", dn.col = "red") 
head(AAPL)
```

```{r}
# data preprocessing
close_prices <- c(matrix(AAPL$AAPL.Close))

# transform data to stationary
diffed <- diff(close_prices, differences = 1)
head(diffed)
```

```{r}
lag_transform <- function(x, k= 1){
  # create data frame with shifted values    
      lagged =  c(rep(NA, k), x[1:(length(x)-k)])
      DF = as.data.frame(cbind(lagged, x))
      colnames(DF) <- c( paste0('x-', k), 'x')
      DF[is.na(DF)] <- 0
      return(DF)
}

supervised <- lag_transform(diffed, 1)
head(supervised)
```

```{r}
# split into train and test sets
N <- nrow(supervised)
n <- round(N *0.7, digits = 0)
train <- supervised[1:n, ]
test  <- supervised[(n+1):N,  ]
```

```{r}
# normalize data
scale_data <- function(train, test, feature_range = c(0, 1)) {
  # scales the data between 0 and 1
  x = train
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_train = ((x - min(x) ) / (max(x) - min(x)  ))
  std_test  = ((test - min(x) ) / (max(x) - min(x)  ))
  
  scaled_train = std_train *(fr_max -fr_min) + fr_min
  scaled_test = std_test *(fr_max -fr_min) + fr_min
  
  return( list(scaled_train = as.vector(scaled_train), scaled_test = as.vector(scaled_test) ,scaler= c(min =min(x), max = max(x))) )
}

Scaled <- scale_data(train, test, c(-1, 1))

y_train <- Scaled$scaled_train[, 2]
x_train <- Scaled$scaled_train[, 1]

y_test <- Scaled$scaled_test[, 2]
x_test <- Scaled$scaled_test[, 1]
```

```{r}
invert_scaling = function(scaled, scaler, feature_range = c(0, 1)){
  # reverts scaled data back into its original form
  min = scaler[1]
  max = scaler[2]
  t = length(scaled)
  mins = feature_range[1]
  maxs = feature_range[2]
  inverted_dfs = numeric(t)
  
  for( i in 1:t){
    X = (scaled[i]- mins)/(maxs - mins)
    rawValues = X *(max - min) + min
    inverted_dfs[i] <- rawValues
  }
  return(inverted_dfs)
}
```

```{r}
# define the model

# Reshape the input to 3-dim
dim(x_train) <- c(length(x_train), 1, 1)

# specify required arguments
X_shape2 = dim(x_train)[2]
X_shape3 = dim(x_train)[3]
batch_size = 1                # must be a common factor of both the train and test samples
units = 1                     # can adjust this, in model tuninig phase

#=========================================================================================

model <- keras_model_sequential() 
model%>%
  layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful= TRUE)%>%
  layer_dense(units = 1)
```

```{r}
# compile model
model %>% compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam( lr= 0.02, decay = 1e-6 ),  
  metrics = c('accuracy')
)
```

```{r}
# fit model
Epochs = 50   
for(i in 1:Epochs ){
  model %>% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)
  model %>% reset_states()
}
```

```{r}
# make predictions
L = length(x_test)
scaler = Scaled$scaler
predictions = numeric(L)

for(i in 1:L){
     X = x_test[i]
     dim(X) = c(1,1,1)
     yhat = model %>% predict(X, batch_size=batch_size)
     # invert scaling
     yhat = invert_scaling(yhat, scaler,  c(-1, 1))
     # invert differencing
     yhat  = yhat + close_prices[(n+i)]
     # store
     predictions[i] <- yhat
}
```

```{r}
# plotting lib
library(tidyquant)
library(scales)
library(lubridate)
```

```{r}
close_dates <- rownames(data.frame(AAPL$AAPL.Close))
#close_dates <- as.Date(dates$Ymd, format = "%Y-%m-%d")
train_idx <- 1:as.numeric(length(close_dates) - nrow(test))
train_data <- data.frame(cbind(close_dates[train_idx], close_prices[train_idx]))
test_data <- data.frame(cbind(close_dates[-train_idx], close_prices[-train_idx]))
predict_data <- data.frame(cbind(close_dates[-train_idx], predictions))
names <- c("date", "close")

colnames(train_data) <- names
colnames(test_data) <- names
colnames(predict_data) <- names

train_data$date <- as.Date(train_data$date, format = "%Y-%m-%d")
test_data$date <- as.Date(test_data$date, "%Y-%m-%d")
predict_data$date <- as.Date(predict_data$date, "%Y-%m-%d")

train_data$close <- as.numeric(matrix(train_data$close))
test_data$close <- as.numeric(matrix(test_data$close))
predict_data$close <- as.numeric(matrix(predict_data$close))

```

```{r}
ggplot() + 
  geom_line(data = train_data, aes(x = date, y = close), color = "blue") +
  geom_line(data = test_data, aes(x = date, y = close), color = "red") + 
  geom_line(data = predict_data, aes(x = date, y = close), size = 1, color = "green", linetype = "longdash") + 
  scale_color_manual(values = c("train", "test", "predict")) + 
  labs(title = "AAPL", y = "Closing Price", x = "") + 
  theme_tq() 
```

